{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":821251,"sourceType":"datasetVersion","datasetId":430934}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:18.742565Z","iopub.execute_input":"2025-01-31T08:03:18.743039Z","iopub.status.idle":"2025-01-31T08:03:18.756037Z","shell.execute_reply.started":"2025-01-31T08:03:18.743005Z","shell.execute_reply":"2025-01-31T08:03:18.754939Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#pip install pandas-profiling==3.6.6 pydantic==1.10.11","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:18.757528Z","iopub.execute_input":"2025-01-31T08:03:18.757891Z","iopub.status.idle":"2025-01-31T08:03:18.766274Z","shell.execute_reply.started":"2025-01-31T08:03:18.757848Z","shell.execute_reply":"2025-01-31T08:03:18.765304Z"},"_kg_hide-output":true,"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# !pip install pyforest\n# 1-Import Libraies\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nimport datetime as dt\n#%matplotlib inline\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nimport missingno as msno \nimport plotly.express as px\nimport plotly.graph_objects as go\n#import datetime\n\nfrom sklearn.compose import make_column_transformer\n\n# Scaling\nfrom sklearn.preprocessing import scale \nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import PowerTransformer \nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import RobustScaler\n\n# Modelling\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import silhouette_score\n\n# Importing plotly and cufflinks in offline mode\nimport cufflinks as cf\nimport plotly.offline\ncf.go_offline()\ncf.set_config_file(offline=False, world_readable=True)\nimport plotly.graph_objects as go\n\n# Ignore Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.warn(\"this will not show\")\n\n# Figure&Display options\nplt.rcParams[\"figure.figsize\"] = (16, 9)\npd.set_option('max_colwidth',200)\npd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 200)\npd.set_option('display.float_format', lambda x: '%.2f' % x)\n\n# !pip install termcolor\nimport colorama\nfrom colorama import Fore, Style  # makes strings colored\nfrom termcolor import colored\nfrom termcolor import cprint\n\nimport ipywidgets\nfrom ipywidgets import interact\n\n# !pip install -U pandas-profiling --user\n#import pandas_profiling\n#from pandas_profiling.report.presentation.flavours.html.templates import create_html_assets\n\n# !pip install wordcloud\nfrom wordcloud import WordCloud\n\n# !pip install squarify\nimport squarify as sq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:18.768464Z","iopub.execute_input":"2025-01-31T08:03:18.768796Z","iopub.status.idle":"2025-01-31T08:03:18.794716Z","shell.execute_reply.started":"2025-01-31T08:03:18.768766Z","shell.execute_reply":"2025-01-31T08:03:18.793546Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Introduction","metadata":{}},{"cell_type":"markdown","source":"The aim of this study is to enhance customer retention and boost sales revenues through the application of RFM Analysis and K-Means Clustering for effective customer segmentation.\n\nThis analysis leverages a dataset containing transaction records from a UK-based online retail company. The data spans from 1st December 2009 to 9th December 2011 and includes transactions involving unique, all-occasion giftware. The company's customer base primarily consists of wholesalers.","metadata":{}},{"cell_type":"markdown","source":"# Methodology","metadata":{}},{"cell_type":"markdown","source":"This project employed a structured methodology to achieve comprehensive customer segmentation and analysis. Initial exploratory data analysis (EDA) and visualisation identified missing values and patterns, enabling data cleaning and preparation for further analyses. Descriptive analysis revealed key trends, such as the UK contributing the highest sales revenue, guiding the focus on UK transactions.\n\nK-Means clustering for RFM segmentation was used to automatically group customers based on patterns in their RFM scores (recency, frequency, and monetary values), and it may provide more flexibility than rule-based segmentation by identifying clusters that are not predefined. This was further refined using the K-Means clustering algorithm, which uncovered hidden patterns in the RFM data. Preprocessing steps like scaling, normalisation, and determining the optimal number of clusters (via the Elbow Method and Silhouette Analysis) ensured robust clustering. Visualisation techniques with scatter plots used in interpreting and labelling clusters.\n\nFinally, Cohort Analysis grouped customers by shared characteristics or purchase timing, enabling insights into retention, churn, and customer lifetime value. These insights complemented RFM and clustering results, offering a holistic understanding of customer behaviour to drive engagement and sales performance.","metadata":{}},{"cell_type":"markdown","source":"# Data Cleaning with Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/online-retail-ii-uci/online_retail_II.csv\")","metadata":{"execution":{"iopub.status.busy":"2025-01-31T08:03:18.796383Z","iopub.execute_input":"2025-01-31T08:03:18.796693Z","iopub.status.idle":"2025-01-31T08:03:20.351272Z","shell.execute_reply.started":"2025-01-31T08:03:18.796665Z","shell.execute_reply":"2025-01-31T08:03:20.349345Z"},"_kg_hide-input":true,"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Preliminary Insights**\n\nThere are 8 data fields in the dataset, comprising 5 categorical and 3 numerical variables. \n\nMissing values are found in two columns, 'Desciptions' and 'Customer ID'.\n\nNegative values existed in the columns 'Quantity' and 'Price'.\n\nDuplicate rows are detected in 34,335 rows.\n\nAmong 43 consumer countries, United Kingdom is the top consumer of the UK-based online retail company, forming 92% of the transaction records (981,330 out of 1,067,371 records).\n\nThe Customer ID is detected as a numerical object, but it should be treated as an object variable, as it serves as a unique identifier for each customer.","metadata":{}},{"cell_type":"code","source":"    print(\"First 5 rows of the DataFrame:\")\n    print(df.head())\n    print(\"\\nDataFrame Information:\")\n    print(df.info())\n    print(\"\\nUnique values\")\n    print(df.nunique())\n    print(\"\\nSummary Statistics:\")\n    print(df.describe())\n    print(df.describe(include=object))\n    print(\"\\nMissing Values per Column:\")\n    print(df.isnull().sum())\n    print(df.isnull().sum() / df.isnull().count())\n    print(\"\\nNumber of duplicate rows\")\n    print(df.duplicated(subset=None, keep='first').sum())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:20.352601Z","iopub.execute_input":"2025-01-31T08:03:20.352997Z","iopub.status.idle":"2025-01-31T08:03:23.213906Z","shell.execute_reply.started":"2025-01-31T08:03:20.352958Z","shell.execute_reply":"2025-01-31T08:03:23.210473Z"},"_kg_hide-input":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Negative Quantities in Transactions**\n\nThe majority of records with negative quantities (19,493 out of 22,950) are likely cancelled transactions, as indicated by invoice numbers starting with the letter \"C\".\n\nThe remaining records appear to represent incomplete or invalid entries, as all records with negative quantities and invoice numbers not starting with the letter \"C\" have missing values in the 'Customer ID' column.","metadata":{}},{"cell_type":"code","source":"df[df['Quantity'] < 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:23.214914Z","iopub.execute_input":"2025-01-31T08:03:23.215301Z","iopub.status.idle":"2025-01-31T08:03:23.240705Z","shell.execute_reply.started":"2025-01-31T08:03:23.215262Z","shell.execute_reply":"2025-01-31T08:03:23.239470Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Total no. of records with negative quantities\nnegative_quantity_count = (df['Quantity'] < 0).sum()\nprint(f\"Number of rows with Negative Quantity: {negative_quantity_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:23.241878Z","iopub.execute_input":"2025-01-31T08:03:23.242344Z","iopub.status.idle":"2025-01-31T08:03:23.250888Z","shell.execute_reply.started":"2025-01-31T08:03:23.242305Z","shell.execute_reply":"2025-01-31T08:03:23.249757Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Frequency distribution of first character (of invoice number)\ndf['First_Char'] = df['Invoice'].str[0] \ndf[df['Quantity']<0]['First_Char'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:23.251894Z","iopub.execute_input":"2025-01-31T08:03:23.252297Z","iopub.status.idle":"2025-01-31T08:03:23.767143Z","shell.execute_reply.started":"2025-01-31T08:03:23.252259Z","shell.execute_reply":"2025-01-31T08:03:23.766119Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Non-C negative quantity transactions\ndf[(df['First_Char'] != 'C') & (df['Quantity'] < 0)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:23.770675Z","iopub.execute_input":"2025-01-31T08:03:23.770964Z","iopub.status.idle":"2025-01-31T08:03:23.868646Z","shell.execute_reply.started":"2025-01-31T08:03:23.770940Z","shell.execute_reply":"2025-01-31T08:03:23.867657Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check if all non-C negative quantity transactions have missing customer ID\ndf[(df['First_Char'] != 'C') & (df['Quantity'] < 0)]['Customer ID'].isnull().all()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:23.870674Z","iopub.execute_input":"2025-01-31T08:03:23.870959Z","iopub.status.idle":"2025-01-31T08:03:23.961896Z","shell.execute_reply.started":"2025-01-31T08:03:23.870936Z","shell.execute_reply":"2025-01-31T08:03:23.960802Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Negative Prices in Transactions**\n\nThere are 5 transaction records in the dataset with negative prices and missing Customer ID. \n\nThe 5 records are used to 'adjust bad debt' as indicated in the Desciption column.","metadata":{}},{"cell_type":"code","source":"# Negative price transactions\ndf[df['Price'] < 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:23.962968Z","iopub.execute_input":"2025-01-31T08:03:23.963403Z","iopub.status.idle":"2025-01-31T08:03:23.981476Z","shell.execute_reply.started":"2025-01-31T08:03:23.963361Z","shell.execute_reply":"2025-01-31T08:03:23.980198Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Frequency Distribution of First Character (of invoice number)\ndf[df['Price']<0]['First_Char'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:23.982648Z","iopub.execute_input":"2025-01-31T08:03:23.983045Z","iopub.status.idle":"2025-01-31T08:03:24.001793Z","shell.execute_reply.started":"2025-01-31T08:03:23.983009Z","shell.execute_reply":"2025-01-31T08:03:24.000481Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Frequency Distribution of Description\ndf[df['Price']<0]['Description'].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:24.003226Z","iopub.execute_input":"2025-01-31T08:03:24.003602Z","iopub.status.idle":"2025-01-31T08:03:24.015430Z","shell.execute_reply.started":"2025-01-31T08:03:24.003567Z","shell.execute_reply":"2025-01-31T08:03:24.014146Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Converting Customer ID Column**\n\nThe Customer ID column is converted from numerical to object data type, as it represents unique identifier for each customer.","metadata":{}},{"cell_type":"code","source":"df['Customer ID']=df['Customer ID'].astype('object')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:24.016590Z","iopub.execute_input":"2025-01-31T08:03:24.016969Z","iopub.status.idle":"2025-01-31T08:03:24.085399Z","shell.execute_reply.started":"2025-01-31T08:03:24.016938Z","shell.execute_reply":"2025-01-31T08:03:24.084125Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Handling Duplicates**\n\nTo prepare the dataset for analysis, 34,335 duplicate rows were removed.\n\nFollowing this, there was a slight reduction in the number of missing values in the 'Description' and 'Customer ID' columns, as these records were part of the duplicates removed.","metadata":{}},{"cell_type":"code","source":"df.drop_duplicates(keep='first', inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:24.086362Z","iopub.execute_input":"2025-01-31T08:03:24.086636Z","iopub.status.idle":"2025-01-31T08:03:24.993244Z","shell.execute_reply.started":"2025-01-31T08:03:24.086613Z","shell.execute_reply":"2025-01-31T08:03:24.992121Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nNumber of duplicate rows\")\nprint(df.duplicated(subset=None, keep='first').sum())\nprint(\"\\nMissing Values per Column:\")\nprint(df.isnull().sum())\nprint(\"\\nDataFrame Information:\")\nprint(df.info())\nprint(\"\\nUnique values\")\nprint(df.nunique())\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\nprint(df.describe(include=object))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:24.994166Z","iopub.execute_input":"2025-01-31T08:03:24.994485Z","iopub.status.idle":"2025-01-31T08:03:28.130062Z","shell.execute_reply.started":"2025-01-31T08:03:24.994461Z","shell.execute_reply":"2025-01-31T08:03:28.129143Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Handling Missing Values**\n\nA total of 235,151 rows with missing Customer IDs were dropped, as these rows could not be accurately linked to specific customers and likely represent incomplete or invalid records.\n\nAfter this process:\n\n* The 'Description' column no longer contains missing values, as transactions with missing descriptions also had missing Customer IDs.\n* The 'Price' column no longer contains negative values, as the five transactions with negative values were among the removed records.","metadata":{}},{"cell_type":"code","source":"df.dropna(subset=['Customer ID'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:28.130948Z","iopub.execute_input":"2025-01-31T08:03:28.131189Z","iopub.status.idle":"2025-01-31T08:03:28.275770Z","shell.execute_reply.started":"2025-01-31T08:03:28.131168Z","shell.execute_reply":"2025-01-31T08:03:28.274847Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nMissing Values per Column:\")\nprint(df.isnull().sum())\nprint(\"\\nDataFrame Information:\")\nprint(df.info())\nprint(\"\\nUnique values\")\nprint(df.nunique())\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\nprint(df.describe(include=object))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:28.276601Z","iopub.execute_input":"2025-01-31T08:03:28.276868Z","iopub.status.idle":"2025-01-31T08:03:30.069185Z","shell.execute_reply.started":"2025-01-31T08:03:28.276847Z","shell.execute_reply":"2025-01-31T08:03:30.068331Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Handling Negative Quantities**\n\nA total of 18,390 records with negative quantities were removed, as they represent cancelled, incomplete or invalid transactions that are not relevant to the customer segmentation analysis.","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"#Total no. of records with negative quantities\nnegative_quantity_count = df[df['Quantity'] < 0].shape[0]\nprint(f\"Number of rows with Negative Quantity: {negative_quantity_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:30.070176Z","iopub.execute_input":"2025-01-31T08:03:30.070564Z","iopub.status.idle":"2025-01-31T08:03:30.085745Z","shell.execute_reply.started":"2025-01-31T08:03:30.070528Z","shell.execute_reply":"2025-01-31T08:03:30.084728Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Remove records with negative quantity\ndf=df[df['Quantity'] > 0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:30.086829Z","iopub.execute_input":"2025-01-31T08:03:30.087164Z","iopub.status.idle":"2025-01-31T08:03:30.160456Z","shell.execute_reply.started":"2025-01-31T08:03:30.087136Z","shell.execute_reply":"2025-01-31T08:03:30.159554Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"\\nDataFrame Information:\")\nprint(df.info())\nprint(\"\\nUnique values\")\nprint(df.nunique())\nprint(\"\\nSummary Statistics:\")\nprint(df.describe())\nprint(df.describe(include=object))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:30.161440Z","iopub.execute_input":"2025-01-31T08:03:30.161770Z","iopub.status.idle":"2025-01-31T08:03:31.699727Z","shell.execute_reply.started":"2025-01-31T08:03:30.161738Z","shell.execute_reply":"2025-01-31T08:03:31.698591Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Exploratory Data Analysis","metadata":{}},{"cell_type":"markdown","source":"**Insights**\n\nBar charts showed that the UK contributed the majority of both sales revenue and customer numbers. Therefore, the analysis focuses on UK-based transactions to provide more targeted insights into performance and trends, ensuring the findings are relevant and actionable for the business’s core market.","metadata":{}},{"cell_type":"code","source":"df['Monetary'] = df['Quantity'] * df['Price']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:31.700662Z","iopub.execute_input":"2025-01-31T08:03:31.700990Z","iopub.status.idle":"2025-01-31T08:03:31.709395Z","shell.execute_reply.started":"2025-01-31T08:03:31.700964Z","shell.execute_reply":"2025-01-31T08:03:31.708435Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Top 10 Countries by Customers\ndfg1 = df.groupby('Country')[\"Customer ID\"].nunique().sort_values(ascending=False).head(10)\nplt.figure(figsize=(10, 6))\nplt.bar(dfg1.index, dfg1, color='skyblue')\nplt.title(\"Top 10 Countries by Customers\")\nplt.xlabel(\"Countries\")\nplt.ylabel(\"Total Number of Customers\")\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:31.710298Z","iopub.execute_input":"2025-01-31T08:03:31.710626Z","iopub.status.idle":"2025-01-31T08:03:32.254856Z","shell.execute_reply.started":"2025-01-31T08:03:31.710601Z","shell.execute_reply":"2025-01-31T08:03:32.253806Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Top 10 Products by Sales\nproduct_sales = df.groupby('Description')['Quantity'].sum().sort_values(ascending=False).head(10)\nplt.figure(figsize=(10, 6))\nproduct_sales.plot(kind='bar', color='skyblue')\nplt.title('Top 10 Products by Sales')\nplt.xlabel('Product Description')\nplt.ylabel('Total Quantity Sold')\nplt.xticks(rotation=45, ha='right')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:32.255743Z","iopub.execute_input":"2025-01-31T08:03:32.255999Z","iopub.status.idle":"2025-01-31T08:03:32.652723Z","shell.execute_reply.started":"2025-01-31T08:03:32.255977Z","shell.execute_reply":"2025-01-31T08:03:32.651766Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"## Sales by Country\ncountry_sales = df.groupby('Country')['Monetary'].sum().sort_values(ascending=False).head(10) / 1e6\nplt.figure(figsize=(10, 6))\ncountry_sales.plot(kind='bar', color='lightgreen')\nplt.title('Top 10 Countries by Sales (in Millions)')\nplt.xlabel('Country')\nplt.ylabel('Total Sales (£M)')\nplt.xticks(rotation=45, ha='right')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:32.653674Z","iopub.execute_input":"2025-01-31T08:03:32.653932Z","iopub.status.idle":"2025-01-31T08:03:33.000185Z","shell.execute_reply.started":"2025-01-31T08:03:32.653910Z","shell.execute_reply":"2025-01-31T08:03:32.999145Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Section 1: Customer Segmentation Using RFM Analysis","metadata":{}},{"cell_type":"markdown","source":"# RFM Distributions","metadata":{}},{"cell_type":"markdown","source":"RFM (Recency, Frequency, Monetary) Analysis was conducted to segment customers based on three key dimensions: recency (time since the last purchase), frequency (total number of purchases), and monetary value (total amount spent). These metrics are essential for identifying valuable customers and uncovering opportunities for targeted marketing campaigns.\n\nHistograms were used to visualise the distributions of each of the three RFM variables. The **recency distribution** is heavily skewed to the right, with the majority of customers showing low recency values. This indicates that a significant portion of customers have made recent purchases, reflecting strong engagement. However, a long tail of customers who have not purchased for an extended period suggests opportunities for re-engagement through tailored campaigns.\n\nThe **frequency distribution** is also highly right-skewed, with most customers having made very few transactions. A small subset of customers accounts for frequent purchases, reflecting the \"80–20 rule,\" where a minority of customers drive the majority of business activity. This highlights an opportunity to convert low-frequency buyers into more regular purchasers through loyalty programmes, special offers, or other engagement strategies.\n\nSimilarly, the **monetary distribution** shows a pronounced right skew. While a small group of high-value customers contributes significantly to overall revenue, the majority of customers have relatively low spending levels. This emphasises the importance of nurturing high-value customers with exclusive perks or premium services, while smaller spenders could be incentivised to increase their contributions through personalised promotions and product recommendations.","metadata":{}},{"cell_type":"code","source":"# Focus on UK Market\ndf_uk = df[df['Country'] == 'United Kingdom']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:33.001250Z","iopub.execute_input":"2025-01-31T08:03:33.001545Z","iopub.status.idle":"2025-01-31T08:03:33.137506Z","shell.execute_reply.started":"2025-01-31T08:03:33.001520Z","shell.execute_reply":"2025-01-31T08:03:33.136616Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# RFM Analysis\n## Prepare the data\ndf_uk['InvoiceDate'] = pd.to_datetime(df_uk['InvoiceDate'])\nreference_date = df_uk['InvoiceDate'].max() + pd.Timedelta(days=1)\ndf_uk['Monetary'] = df_uk['Quantity'] * df_uk['Price']\n\nrfm = df_uk.groupby('Customer ID').agg({\n    'InvoiceDate': lambda x: (reference_date - x.max()).days,\n    'Invoice': 'count',\n    'Monetary': 'sum'\n}).rename(columns={\n    'InvoiceDate': 'Recency',\n    'Invoice': 'Frequency',\n    'Monetary': 'Monetary'\n})","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:33.141235Z","iopub.execute_input":"2025-01-31T08:03:33.141540Z","iopub.status.idle":"2025-01-31T08:03:33.885483Z","shell.execute_reply.started":"2025-01-31T08:03:33.141504Z","shell.execute_reply":"2025-01-31T08:03:33.884518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Set the figure size\nplt.figure(figsize=(12, 6))\n\n# Plot histogram for Recency\nplt.subplot(1, 3, 1)\nsns.histplot(rfm['Recency'], kde=True, color='blue')\nplt.title('Distribution of Recency')\nplt.xlabel('Recency (days)')\nplt.ylabel('Frequency')\n\n# Plot histogram for Frequency\nplt.subplot(1, 3, 2)\nsns.histplot(rfm['Frequency'], kde=True, color='green')\nplt.title('Distribution of Frequency')\nplt.xlabel('Frequency (transactions)')\nplt.ylabel('Frequency')\n\n# Plot histogram for Monetary in thousands\nplt.subplot(1, 3, 3)\nsns.histplot(rfm['Monetary'] / 1000, kde=True, color='orange')\nplt.title('Distribution of Monetary (in Thousands)')\nplt.xlabel('Monetary (total spend in thousands)')\nplt.ylabel('Frequency')\n\n# Adjust layout\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:03:33.886666Z","iopub.execute_input":"2025-01-31T08:03:33.886934Z","iopub.status.idle":"2025-01-31T08:03:39.960628Z","shell.execute_reply.started":"2025-01-31T08:03:33.886910Z","shell.execute_reply":"2025-01-31T08:03:39.959458Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# RFM Segmentation with K-Means Clustering","metadata":{}},{"cell_type":"markdown","source":"K-Means Clustering was applied to segment customers into distinct groups based on their RFM data.\n\nBased on Silhouette Scores for evaluating cluster cohesion and separation, 5 clusters were determined to be the optimal number of clusters with the highest average silhouette score. Elbow Method was also used to visualise the Within-Cluster Sum of Squares (WCSS) and to analyse where adding more clusters no longer provided significant improvements.","metadata":{}},{"cell_type":"code","source":"##### Normalize data for clustering\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nrfm_normalized = scaler.fit_transform(rfm)\n\n# K-Means Clustering\n\n# Find the optimal number of clusters using the silhouette method\nsilhouette_scores = []\nfor i in range(2, 11):  # Start from 2 clusters because silhouette score requires at least 2 clusters\n    kmeans = KMeans(n_clusters=i, random_state=42)\n    cluster_labels = kmeans.fit_predict(rfm_normalized)\n    silhouette_avg = silhouette_score(rfm_normalized, cluster_labels)\n    silhouette_scores.append(silhouette_avg)\n\n# Plot the silhouette scores\nplt.figure(figsize=(8, 5))\nplt.plot(range(2, 11), silhouette_scores, marker='o')\nplt.title('Silhouette Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('Silhouette Score')\nplt.show()\n\n## Find the optimal number of clusters using the elbow method\nwcss = []\nfor i in range(1, 11):\n    kmeans = KMeans(n_clusters=i, random_state=42)\n    kmeans.fit(rfm_normalized)\n    wcss.append(kmeans.inertia_)\n\nplt.figure(figsize=(8, 5))\nplt.plot(range(1, 11), wcss, marker='o')\nplt.title('Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()\n\n## Apply K-Means with the chosen number of clusters\noptimal_clusters = 5   # Adjust based on the elbow plot\nkmeans = KMeans(n_clusters=optimal_clusters, random_state=42)\nrfm['Cluster'] = kmeans.fit_predict(rfm_normalized)\n\n# Define a distinct colour palette\npalette = sns.color_palette(\"tab10\")  # Ensure this line is executed before using it\n\n# Visualize clusters\nsns.pairplot(rfm, hue='Cluster', diag_kind='kde',palette=palette)\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:05:52.504687Z","iopub.execute_input":"2025-01-31T08:05:52.505063Z","iopub.status.idle":"2025-01-31T08:06:18.939039Z","shell.execute_reply.started":"2025-01-31T08:05:52.505032Z","shell.execute_reply":"2025-01-31T08:06:18.937900Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Cluster Analysis","metadata":{}},{"cell_type":"markdown","source":"We generated charts with log-transformed Recency, Frequency, and Monetary values to visualise the natural clusters. The application of a logarithmic transformation helped to increase clusters visibility, as the Monetary and Frequency values have extreme ranges that resulted in overlapping colours and data points which make it harder to differentiate them clearly.\n\n**Cluster 0 (Orange in the charts):**\nCustomers in this cluster (the largest cluster of 3,306 customers) demonstrate high Frequency and Monetary values, though their Recency (recent activity) is relatively low. These individuals are classified as **Champions or Loyal Customers.** To maintain their loyalty, it is essential to reward them with special offers, request reviews, encourage the purchase of premium products, or send personalized gifts or cards.\n\n**Cluster 1 (Blue in the charts):**\nCustomers in this segment (second largest segment of 1,760 customers) have moderate Frequency and Monetary values, with low Recency. They are still somewhat recent in their activity but do not engage as frequently or with the same spending levels as Cluster 0. These customers are categorized as **Promising or New Customers**. To foster a deeper relationship, it is recommended to offer loyalty programs, provide tailored product recommendations, or send personalized messages.\n\n**Cluster 2 (Green in the charts):**\nThis group of customers (275 customers) exhibits lower Frequency, moderate Monetary values, and higher Recency, suggesting that their activity is less recent. These customers fall into the **Need Attention or Shouldn't Lose** category. To re-engage them, businesses should offer limited-time discounts, recommend new products, or send surveys to rekindle their interest and encourage return visits.\n\n**Cluster 3 (Red in the charts):**\nCustomers in this cluster (7 customers) very high Frequency and Monetary values, with moderate to high Recency. While they were once highly engaged, their activity has decreased in recent times. These individuals are categorized as **Shouldn't Lose**. To prevent losing them to competitors, it is crucial to deploy special offers, initiate direct outreach, and send surveys to re-establish the connection and retain their business.\n\n**Cluster 4 (Purple in the charts):**\nThis group (5 customers) is characterized by very low Frequency and Monetary values but very high Recency, indicating that they have been inactive for a significant period. These customers are classified as **Sleepers or Lost**. For these individuals, reactivation campaigns should be implemented to try to bring them back into the fold. However, if they are deemed truly lost, it may be necessary to exclude them from future targeting efforts.","metadata":{}},{"cell_type":"code","source":"rfm['Log_Monetary'] = np.log1p(rfm['Monetary'])\nrfm['Log_Frequency'] = np.log1p(rfm['Frequency'])\nrfm['Log_Recency'] = np.log1p(rfm['Recency'])\n\nsns.pairplot(rfm[['Log_Recency', 'Log_Frequency', 'Log_Monetary', 'Cluster']],\n             hue='Cluster', diag_kind='kde', palette=palette)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:17:15.329902Z","iopub.execute_input":"2025-01-31T08:17:15.330270Z","iopub.status.idle":"2025-01-31T08:17:21.373118Z","shell.execute_reply.started":"2025-01-31T08:17:15.330242Z","shell.execute_reply":"2025-01-31T08:17:21.371990Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Section 2: Retention Trends Through Cohort Analysis","metadata":{}},{"cell_type":"markdown","source":"The cohort analysis provides valuable insights into customer acquisition and retention trends, highlighting both successes and areas for improvement.\n\n**Initial Customer Acquisition**\n\nThe December 2009 cohort is particularly notable, starting with an impressive 904 customers in its first month. This significant influx is likely attributed to year-end promotions or seasonal shopping habits. Early 2010 also saw strong acquisition numbers, though subsequent months showed a gradual decline in cohort sizes. This suggests that while the initial marketing efforts were effective, there may have been a reduction in outreach impact over time.\n\n**Customer Retention**\n\nHowever, retention rates reveal a consistent challenge. Across all cohorts, there is a marked drop in customer engagement after the first month. For instance, the December 2009 cohort retained only 318 customers in its second month - a retention rate of just 35%. This sharp early decline is a recurring pattern, emphasising the need for strategies to engage and retain customers immediately after their initial purchase.\n\nThat said, retention stabilises after the initial drop-off, forming a loyal core of customers. By the sixth month, the December 2009 cohort retained 323 customers, with this figure remaining relatively consistent in subsequent months. This suggests that while early attrition is significant, those who continue to engage tend to remain loyal over the longer term.\n\n**Seasonal or Marketing Impact**\n\nCertain cohorts displayed slightly better retention outcomes. For example, the October 2010 cohort retained 84 customers (25% retention rate) in its second month, suggesting a possible impact of targeted campaigns or special events during that period. In contrast, cohorts from late 2011 showed weaker performance in both initial acquisition numbers (as low as 15$) and long-term retention, potentially reflecting a decline in marketing efforts or changes in customer behaviour.","metadata":{}},{"cell_type":"code","source":"# Cohort Analysis\n## Extract Year and Month from InvoiceDate\ndf_uk['InvoiceMonth'] = df_uk['InvoiceDate'].dt.to_period('M')\ndf_uk['CohortMonth'] = df_uk.groupby('Customer ID')['InvoiceDate'].transform('min').dt.to_period('M')\n\n## Calculate Cohort Index\ndef cohort_index(df):\n    invoice_year, invoice_month = df['InvoiceMonth'].dt.year, df['InvoiceMonth'].dt.month\n    cohort_year, cohort_month = df['CohortMonth'].dt.year, df['CohortMonth'].dt.month\n    return (invoice_year - cohort_year) * 12 + (invoice_month - cohort_month) + 1\n\ndf_uk['CohortIndex'] = cohort_index(df_uk)\n\n## Create the Cohort Table\ncohort_table = df_uk.groupby(['CohortMonth', 'CohortIndex'])['Customer ID'].nunique().unstack(0)\n\n## Visualize the Cohort Table\nplt.figure(figsize=(12, 8))\nsns.heatmap(cohort_table.T, annot=True, fmt='.0f', cmap='viridis')\nplt.title('Cohort Analysis')\nplt.ylabel('Cohort Month')\nplt.xlabel('Cohort Index')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:11:45.523694Z","iopub.execute_input":"2025-01-31T08:11:45.524035Z","iopub.status.idle":"2025-01-31T08:11:47.103500Z","shell.execute_reply.started":"2025-01-31T08:11:45.524009Z","shell.execute_reply":"2025-01-31T08:11:47.102290Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Actionable Recommendations","metadata":{}},{"cell_type":"markdown","source":"These findings underscore the importance of focusing on early retention to address the steep drop-off in customer engagement after the first month. Introducing strategies such as loyalty programmes, personalised follow-ups, and exclusive offers could help improve these rates. Seasonal trends, such as those observed in December 2009, also demonstrate the potential to maximise customer acquisition during peak shopping periods. Furthermore, analysing the behaviours and preferences of long-term loyal customers could provide actionable insights to replicate this success across future cohorts.\n\nUltimately, while customer acquisition is crucial, retention is equally essential and requires deliberate effort and strategic planning. By addressing the challenges identified in this analysis, businesses can build a more robust foundation for sustainable growth and customer loyalty.","metadata":{}},{"cell_type":"markdown","source":"# Summary Statistics","metadata":{}},{"cell_type":"code","source":"# Summary Statistics\nprint(rfm.head())\nprint(\"Cluster Sizes:\\n\", rfm['Cluster'].value_counts())\nprint(cohort_table.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-31T08:11:47.104809Z","iopub.execute_input":"2025-01-31T08:11:47.105119Z","iopub.status.idle":"2025-01-31T08:11:47.122378Z","shell.execute_reply.started":"2025-01-31T08:11:47.105094Z","shell.execute_reply":"2025-01-31T08:11:47.121193Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Conclusion","metadata":{}},{"cell_type":"markdown","source":"This study demonstrates the effectiveness of combining RFM Analysis with K-Means Clustering for customer segmentation, enabling businesses to derive deeper insights into purchasing behaviour and optimise engagement strategies. Unlike traditional rule-based RFM segmentation, which relies on predefined thresholds to classify customers, K-Means Clustering automatically identifies natural groupings in the data. This data-driven approach enhances flexibility and accuracy, allowing for more refined segmentation that adapts to underlying customer behaviours rather than rigid classification rules.\n\nThe findings reveal distinct customer clusters, highlighting opportunities for targeted retention and marketing strategies. Notably, high-value and frequent buyers (Cluster 0) form the largest group, while smaller clusters represent niche customer segments that require personalised engagement tactics. Cohort analysis further underscores the importance of early retention efforts, as significant customer drop-offs occur after the first purchase, reinforcing the need for strategic follow-ups and loyalty programmes.","metadata":{}}]}